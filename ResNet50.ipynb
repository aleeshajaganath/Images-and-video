{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleeshajaganath/Images-and-video/blob/master/ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7suUr01BWorA",
        "colab_type": "text"
      },
      "source": [
        "*gdrive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJe_09S5y5ye",
        "colab_type": "code",
        "outputId": "93a33ce2-4178-4270-85ad-ce2315d4684a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-72lQGmy8YX",
        "colab_type": "code",
        "outputId": "ec40701a-e9ee-455c-87a1-91537670b8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd gdrive/My Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyIKdUeXEDsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKaeLHrJIZUs",
        "colab_type": "code",
        "outputId": "33f45865-e1d2-4189-e28e-1b528d6e80f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "for file in fileList:\n",
        "    #print(file)\n",
        "   #\n",
        "   try:\n",
        "    imgfile = Image.open(file) # \n",
        "    #print(i)\n",
        "    i=i+1#    imgfile.show()\n",
        "    img = load_img(file, grayscale=False, target_size=(64, 64,3))\n",
        "    \n",
        "                  \n",
        "    img = img_to_array(img)\n",
        "                  \n",
        "    #\n",
        "    #img = img.reshape(64, 64,3)\n",
        "    #150, 150, 3\n",
        "                  \n",
        "    img = img.astype('float32')\n",
        "                  \n",
        "    #\n",
        "    img = img / 255.0\n",
        "                  \n",
        "    value = img.flatten()\n",
        "                  \n",
        "    with open(\"validation.csv\", 'a') as f:\n",
        "                      \n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(value)\n",
        "      \n",
        "   except OSError as e:\n",
        "        print(\"last file is\"+file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OENqFQLBgzI8",
        "colab_type": "text"
      },
      "source": [
        "**trainX.csv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwqH5jOsg0jd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Nv3zN_FCZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "for file in fileList:\n",
        "    #print(file)\n",
        "   #\n",
        "   try:\n",
        "    imgfile = Image.open(file) # \n",
        "    #print(i)\n",
        "    i=i+1#    imgfile.show()\n",
        "    img = load_img(file, grayscale=False, target_size=(64, 64,3))\n",
        "    \n",
        "                  \n",
        "    img = img_to_array(img)\n",
        "                  \n",
        "    #\n",
        "    #img = img.reshape(64, 64,3)\n",
        "    #150, 150, 3\n",
        "                  \n",
        "    img = img.astype('float32')\n",
        "                  \n",
        "    #\n",
        "    img = img / 255.0\n",
        "                  \n",
        "    value = img.flatten()\n",
        "                  \n",
        "    with open(\"training_check.csv\", 'a') as f:\n",
        "                      \n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(value)\n",
        "      \n",
        "   except OSError as e:\n",
        "        print(\"last file is\"+file)\n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEnQXJfOhqQU",
        "colab_type": "text"
      },
      "source": [
        "checking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inf6m7kJh5A7",
        "colab_type": "text"
      },
      "source": [
        "RESNET50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdOlTW8JDB8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Aug 19 00:21:40 2019\n",
        "\n",
        "@author: user\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "#%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)\n",
        "\n",
        "\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    \n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut]) \n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(F2, (f, f), strides = (1,1),padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(F3, (1,1), strides = (1,1),name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)conv_name_base + '1'\n",
        "    X_shortcut=Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "   \n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "def ResNet50(input_shape = (64, 64, 3), classes = 224):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128,128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128,128, 512], stage=3, block='b')\n",
        "    X =identity_block(X, 3, [128,128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128,128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256,256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256,256, 1024], stage=4, block='b')\n",
        "    X =identity_block(X, 3, [256,256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256,256, 1024], stage=4, block='d')\n",
        "    X =identity_block(X, 3, [256,256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256,256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512,512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512,512, 2048], stage=5, block='b')\n",
        "    X =identity_block(X, 3, [512,512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(X)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcGX-ycxIG6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "from resnets_utils import *\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ns2vEYeHATh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO-bQElM2KF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train= pd.read_csv('trainY_1.csv',sep=',')\n",
        "Y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB3VyNMVIjKF",
        "colab_type": "code",
        "outputId": "207f7917-2d55-48ec-ec20-7187b04d1588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import math\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "Y_test= pd.read_csv('ta1.csv',sep=',')\n",
        "X_test= pd.read_csv('validationX1.csv',sep=',')\n",
        "Y_train= pd.read_csv('ta.txt',sep=',')\n",
        "X_train= pd.read_csv('trainX1.csv',sep=',')\n",
        "\n",
        "\n",
        "\n",
        "#X_train, Y_train, X_test, Y_test_orig, classes = load_dataset()\n",
        "\n",
        "#print(X_train_orig.shape)\n",
        "# Normalize image vectors\n",
        "#X_train = X_train_orig/255.\n",
        "#X_test = X_test_orig/255.\n",
        "\n",
        "# Convert training and test labels to one hot matrices\n",
        "#Y_train = to_categorical(Y_train_orig).reshape((1080, 6))\n",
        "#Y_test = to_categorical(Y_test_orig).reshape((120, 6))\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 14719\n",
            "number of test examples = 2999\n",
            "X_train shape: (14719, 12288)\n",
            "Y_train shape: (14718, 224)\n",
            "X_test shape: (2999, 12288)\n",
            "Y_test shape: (2999, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whgfuyN4TAzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_tDaio3bFXD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "Y_train= pd.read_csv('ta.txt',sep=',')\n",
        "Y_test= pd.read_csv('ta1.csv',sep=',')\n",
        "X_train=X_train[:14718]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YrmzoLVC5kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test= pd.read_csv('validationX1.csv',sep=',')\n",
        "\n",
        "X_train= pd.read_csv('trainX1.csv',sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olfgjZxKCPSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=Y_train.to_numpy()\n",
        "Y_test=Y_test.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaZa5xujmnjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_train=np.array(X_train[:][:])\n",
        "Y_test=np.array(Y_test[:][:])\n",
        "Y_train=np.array(Y_train[:][:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wBQ5ZMSnBw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_test=np.array(X_test[:][:])\n",
        "Y_test=np.array(Y_test[:][:])\n",
        "X_test=X_test.reshape([2999,64,64 ,3])\n",
        "X_train=X_train.reshape([14718,64,64 ,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTrjsjShY4yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainX,testX,trainY,testY= train_test_split(X_train,Y_train,test_size=0.20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ReyONKhL5nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet50(input_shape = (64, 64, 3), classes = 224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2Cwo0Wmkz7D",
        "colab_type": "code",
        "outputId": "75042e2a-8748-46a6-842b-75ea629fe34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Ytest.shape\n",
        "print(Y_test.shape,X_test.shape,Y_train.shape,X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2999, 224) (2999, 64, 64, 3) (14718, 224) (14718, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulHpe5lySA-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=X_test.reshape([2999,64,64 ,3])\n",
        "X_train=X_train.reshape([14718,64,64 ,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGneckBcL9Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEtZBR0HLqlu",
        "colab_type": "code",
        "outputId": "ac4f19a8-333d-403b-f4c9-c55a6589508e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "model.fit(X_train , Y_train , epochs = 2, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "14718/14718 [==============================] - 157s 11ms/step - loss: 0.1290 - acc: 0.9741\n",
            "Epoch 2/2\n",
            "14718/14718 [==============================] - 139s 9ms/step - loss: 0.1225 - acc: 0.9742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f77e5e81588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvjuO7ZUkCO0",
        "colab_type": "code",
        "outputId": "50c79317-d72d-48e9-9cb9-f85e3661432f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2999/2999 [==============================] - 6s 2ms/step\n",
            "Loss = 0.11999377537246703\n",
            "Test Accuracy = 0.9743396608421666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ggXEygaIXw6",
        "colab_type": "text"
      },
      "source": [
        "**Using pre trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTikuozNIVFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}